{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "295ba419",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T15:41:05.416285Z",
     "start_time": "2024-08-27T15:41:04.819431Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79ded8cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T15:41:06.651068Z",
     "start_time": "2024-08-27T15:41:05.420232Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.schema import Document\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_openai import ChatOpenAI\n",
    "from openai import OpenAI\n",
    "\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
    "\n",
    "\n",
    "from langchain_upstage import ChatUpstage\n",
    "from langchain_upstage import UpstageEmbeddings # Embeddings\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d8d2c70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T15:41:06.992157Z",
     "start_time": "2024-08-27T15:41:06.652978Z"
    }
   },
   "outputs": [],
   "source": [
    "!rm -rf ./docs/chroma # remove old database files if any|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa4adfc9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T15:41:06.997738Z",
     "start_time": "2024-08-27T15:41:06.994940Z"
    }
   },
   "outputs": [],
   "source": [
    "persist_directory = 'docs/chroma/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80f9c9a",
   "metadata": {},
   "source": [
    "# End to End Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ba66f38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T15:41:08.302313Z",
     "start_time": "2024-08-27T15:41:08.210683Z"
    }
   },
   "outputs": [],
   "source": [
    "persist_directory = 'docs/chroma/'\n",
    "\n",
    "filter_embedding = OllamaEmbeddings(model=\"EEVE-Korean-10.8B-FOR-FILTER:latest\",\n",
    "                                     base_url=\"http://172.17.0.8:11434\")\n",
    "filter_llm = ChatOllama(model=\"EEVE-Korean-10.8B-FOR-FILTER:latest\", base_url=\"http://172.17.0.8:11434\", temperature=0)\n",
    "\n",
    "solar_embedding = UpstageEmbeddings(\n",
    "    api_key=\"up_R7NKyxZ1MIMcogbWOvjsJij6108aS\",\n",
    "    model=\"solar-embedding-1-large\"\n",
    ")\n",
    "\n",
    "solar_llm = ChatUpstage(api_key=\"up_R7NKyxZ1MIMcogbWOvjsJij6108aS\", temperature=0)\n",
    "\n",
    "chat_llm = ChatUpstage(api_key=\"up_R7NKyxZ1MIMcogbWOvjsJij6108aS\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fe6c657",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T15:41:09.539407Z",
     "start_time": "2024-08-27T15:41:09.536466Z"
    }
   },
   "outputs": [],
   "source": [
    "file_list = [\n",
    "    \"contents/cv_mingyu.pdf\",\n",
    "    \"contents/cv_hyunji.pdf\",\n",
    "    \"contents/cv_agung.pdf\", # example resume\n",
    "    \"contents/tmpy6pj9ef9.pdf\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8507d65e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T15:41:15.702836Z",
     "start_time": "2024-08-27T15:41:15.692023Z"
    }
   },
   "outputs": [],
   "source": [
    "def update_vector_db(candidate_num, file_name, filter_embedding=filter_embedding, filter_llm=filter_llm,\n",
    "                     solar_embedding=solar_embedding, solar_llm=solar_llm):\n",
    "    # Load data\n",
    "    loader = PyPDFLoader(file_name)\n",
    "    docs = loader.load()\n",
    "    \n",
    "    # setup splitter --> here we will use recursiveCharacterSplitter\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1500,\n",
    "        chunk_overlap=150,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \"(?<=\\. )\", \" \", \"\"],\n",
    "    )\n",
    "\n",
    "    # get split result\n",
    "    splits = text_splitter.split_documents(docs)\n",
    "    # ---------------------------------------------------------\n",
    "    # First Chain(FILTERING)\n",
    "    # ---------------------------------------------------------\n",
    "    \n",
    "    map_prompt = \"\"\"\n",
    "    You are a helpful AI Filtering engine.\n",
    "    You will be given a single passage of a document resume or curriculum vitae in Korean or English. \n",
    "    This section will be enclosed in triple backticks (```)\n",
    "    AI Filtering engine task is to identify and remove any personal identifiable information (PII) such as phone numbers, emails, web addresses, and physical addresses.\n",
    "    Specifically, if you find a name, replace it with \"Candidate No.{candidate_num}\". \n",
    "    While removing PII, ensure that all job-related information such as education, work experience, skills, and awards are accurately preserved and summarized. \n",
    "    Do not omit any important details related to the candidate's qualifications and experience but you should remove the PII except replaced name.\n",
    "    Do not contain any other information that I didn't ask.\n",
    "\n",
    "    ```{text}```\n",
    "    FULL SUMMARY:\n",
    "    \"\"\"\n",
    "    map_prompt_template = PromptTemplate(template=map_prompt, input_variables=[\"text\", \"candidate_num\"])\n",
    "    \n",
    "    map_chain = load_summarize_chain(llm=filter_llm,\n",
    "                             chain_type=\"stuff\",\n",
    "                             prompt=map_prompt_template)\n",
    "    \n",
    "    \n",
    "    # Make an empty list to hold your summaries\n",
    "    summary_list = []\n",
    "\n",
    "    # Loop through a range of the lenght of your splits\n",
    "    for i, doc in enumerate(splits):\n",
    "\n",
    "        # Go get a summary of the chunk\n",
    "        chunk_summary = map_chain.invoke({\"input_documents\": [doc], \"text\": doc.page_content, \"candidate_num\": candidate_num})\n",
    "\n",
    "        # Append that summary to your list\n",
    "        summary_text = chunk_summary['output_text']\n",
    "        summary_list.append(summary_text)\n",
    "        \n",
    "        print(f\"Preview: {summary_text}\"+\"...\",\"\\n\")\n",
    "        print(\"==================================================================\")\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # Second Chain(SUMMARY)\n",
    "    # ---------------------------------------------------------\n",
    "    \n",
    "    \n",
    "    summaries = \"\\n\".join(summary_list)\n",
    "    \n",
    "    # Convert it back to a document\n",
    "    summaries = Document(page_content=summaries)\n",
    "    \n",
    "    combine_prompt = \"\"\"\n",
    "    You are a helpful AI SCOUT BOT! Your name is scouty.\n",
    "    You will be given a series of summaries from a resume in Korean or English. \n",
    "    The summaries will be enclosed in triple backticks (```)\n",
    "    AI SCOUT BOT goal is to give a verbose summary of less than 4000 characters in Korean only.\n",
    "    Ensure that all important job-related information such as education, work experience, skills, and awards are included.\n",
    "    Only answer it based on a given information.\n",
    "    The reader should be able to grasp what happened in the document for hiring the candidate.\n",
    "    Please begin the summary with the {candidate_num}!\n",
    "\n",
    "    ```{text}```\n",
    "    VERBOSE SUMMARY:\n",
    "    \"\"\"\n",
    "    combine_prompt_template = PromptTemplate(template=combine_prompt, input_variables=[\"candidate_num\", \"text\"])\n",
    "    \n",
    "    resume_chain = load_summarize_chain(llm=solar_llm,\n",
    "                             chain_type=\"stuff\",\n",
    "                             prompt=combine_prompt_template,\n",
    "                             verbose=False # Set this to true if you want to see the inner workings\n",
    "                             )\n",
    "    \n",
    "\n",
    "    output = resume_chain.invoke({\"input_documents\": [summaries], \"candidate_num\": candidate_num, \"text\": summaries})\n",
    "    final_output = output['output_text']\n",
    "    print(final_output)\n",
    "    print(\"----------------------------------------------------------------\")\n",
    "    print(f\"SUMMARY EVALUATION of {candidate_num} :\")\n",
    "    summary_score = evaluate_summary(final_output, summaries.page_content)\n",
    "    print(\"----------------------------------------------------------------\")\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # Third Chain (final chain to vector DB)\n",
    "    # ---------------------------------------------------------\n",
    "    \n",
    "    # setup splitter --> here we will use recursiveCharacterSplitter\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=4000,\n",
    "        chunk_overlap=100,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \"(?<=\\. )\", \" \", \"\"],\n",
    "    )\n",
    "\n",
    "    # get split result\n",
    "    splits_output = text_splitter.split_text(final_output)\n",
    "\n",
    "    vectordb = Chroma.from_texts(\n",
    "        texts=splits_output,\n",
    "        embedding=solar_embedding,\n",
    "        persist_directory=persist_directory\n",
    "    )\n",
    "    \n",
    "    return vectordb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7c2efcb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T15:43:48.488957Z",
     "start_time": "2024-08-27T15:41:17.712295Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preview:  AI Filtering Engine Summary:\n",
      "\n",
      "Candidate No.1 is an aspiring AI engineer with experience in various domains and strong communication and collaboration skills. They have consistently documented their learning journey on Notion and are passionate about acquiring new knowledge and skills through self-improvement and research. Recently, they have been interested in LLM, LoRA, RA G methodologies and have been actively participating in related studies.\n",
      "\n",
      "Education: [Educational background information preserved]... \n",
      "\n",
      "==================================================================\n",
      "Preview:  Candidate No.1 has a Master's degree in Industrial and Data Engineering from Pukyong & Pusan National Universities (2023.03). They also have a Bachelor's degree in System Management Engineering with a major in Technical Data Engineering from Pukyong National University (2017-2023.02).\n",
      "\n",
      "Skills and Certifications:\n",
      "- Data visualization, EDA, statistical analysis, modeling, result analysis, ML pipeline construction, reporting, communication, storytelling skills\n",
      "- Proficient in Python (Python, TensorFlow, Hugging Face), R with basic package usage capabilities, and SQL for simple queries and joins.\n",
      "- ADSP certification obtained (2021.09.24).\n",
      "\n",
      "Research & Projects:\n",
      "- An explainable AI-based methodology for anomaly detection and root cause analysis of ship main engines considering internal sensors and external environmental factors (published in the Journal of The Korean Society of Industrial Engineers, Vol. 49, No. 5).... \n",
      "\n",
      "==================================================================\n",
      "Preview:  AI Filtering Summary:\n",
      "\n",
      "Candidate No.1 has experience in utilizing VAE, LGBM, and SHAP for unsupervised main engine anomaly detection on container ships with over 18 months of operation. They have conducted analysis considering internal and external factors and are currently working on an Ocean Engineer project. The candidate presented a poster at the 2023 Spring Joint Conference of the Korean Society of Industrial and Systems Engineering, focusing on developing a fuel consumption prediction model for carbon emission reduction.\n",
      "\n",
      "They have experience in predicting fuel consumption using sensor data from seven ships with two years and six months of operation, employing ML, AutoML, Bi-LSTM with Attention, XGB, etc. Domain knowledge-based preprocessing and feature engineering were performed, along with the creation of domain-specific metrics (DP E per day, BPE for overall voyage period, VE per voyage).\n",
      "\n",
      "The candidate used MLflow for logging and achieved a MAP E of 8%, which was the company's target performance over three months. They also developed an OCR AI model and practical materials for D T in manufacturing sites. Their skills include OCR, DT, and YOLOv8.... \n",
      "\n",
      "==================================================================\n",
      "Preview:  AI Filtering Summary:\n",
      "\n",
      "Candidate No.1 has experience in data generation and labeling for fire prevention system development. They have generated and labeled indoor smoke data using CCTV and an indoor smoke generator, utilizing CV A T for annotation. Additionally, they participated in a machine learning competition for oil classification in construction equipment, developing an oil condition classification model for real-time monitoring of operating oil conditions in construction machinery. The model can utilize all given features during training but only limited features are available for diagnostic testing. They have also worked on data augmentation and preprocessing tasks related to the project.... \n",
      "\n",
      "==================================================================\n",
      "Preview:  AI Filtering Engine Output:\n",
      "\n",
      "Canidate No.1 has experience in data-driven projects, including the creation of a main engine anomaly detection dashboard for safe vessel navigation and participation in a credit card user delinquency prediction competition using machine learning techniques. They have demonstrated strong leadership skills in managing tasks such as preprocessing, modeling, and result reporting. Additionally, they have gained insights into the importance of feature engineering and handling class imbalanced data.\n",
      "\n",
      "Summary:\n",
      "Canidate No.1 has experience in data-driven projects, including the creation of a main engine anomaly detection dashboard for safe vessel navigation and participation in a credit card user delinquency prediction competition using machine learning techniques. They have demonstrated strong leadership skills in managing tasks such as preprocessing, modeling, and result reporting. Additionally, they have gained insights into the importance of feature engineering and handling class imbalanced data.... \n",
      "\n",
      "==================================================================\n",
      "Preview:  AI Filtering Engine Output:\n",
      "\n",
      "Candidate No.1 has received the following awards and recognitions:\n",
      "\n",
      "* Best Award for Developing a Data-driven Wave Forecast Early Warning Service for Safe Ship Operation, 조선해양 공공데이터 및 빅데이터 활용 경진대회 (한국조선해양기자재연구원 & 부산테크노파크), 2022.12.20\n",
      "* Excellent Award for D A CON 2021 Agricultural Product Price Prediction AI Competition, 한국농수산식품유통공사 주관, 2021.12.09\n",
      "* 대한원격탐사학회장상 for predicting COD 해양오염지수를 예측하고, COD가 크게 증가하는 구역을 선별하여 특별관리해역을 제안함, JOISs 2021 해양과학 빅데이터 활용 경진대회 (해양수산부 주최), 2021.11.12\n",
      "* 입선 for Developing a Parking Demand Prediction Model for Busan Nam-gu, 한국토지주택공사 주관, 2021.10.28... \n",
      "\n",
      "==================================================================\n",
      "후보자 1은 다양한 분야에서 경험을 쌓은 AI 엔지니어로, 커뮤니케이션 및 협업 능력이 뛰어납니다. 그들은 지속적으로 노션에 학습 일지를 작성하며, 자기계발과 연구를 통해 새로운 지식과 기술을 습득하는 데 열정적입니다. 최근에는 LLM, LoRA, RA G 방법론에 관심을 가지고 관련 연구에 적극적으로 참여하고 있습니다.\n",
      "\n",
      "학력:\n",
      "후보자 1은 부경대학교와 부산대학교에서 산업 및 데이터 공학 석사 학위를 취득하였습니다 (2023.03). 또한, 부경대학교에서 시스템 관리 공학 학사 학위를 취득하였으며, 전공은 기술 데이터 공학입니다 (2017-2023.02).\n",
      "\n",
      "기술 및 자격증:\n",
      "- 데이터 시각화, EDA, 통계 분석, 모델링, 결과 분석, ML 파이프라인 구축, 보고, 커뮤니케이션, 스토리텔링 기술\n",
      "- Python (Python, TensorFlow, Hugging Face), R with basic package usage capabilities, and SQL for simple queries and joins에 능숙함\n",
      "- ADSP 자격증 취득 (2021.09.24)\n",
      "\n",
      "연구 및 프로젝트:\n",
      "- 선박 주기관 이상 탐지 및 근본 원인 분석을 위한 설명 가능한 AI 기반 방법론, 내부 센서 및 외부 환경 요인을 고려함 (Journal of The Korean Society of Industrial Engineers, Vol. 49, No. 5에 게재)\n",
      "- 컨테이너 선박에서 18개월 이상의 운영 경험을 통해 VAE, LGBM, SHAP을 활용한 비지도 주기관 이상 탐지 수행\n",
      "- 현재 Ocean Engineer 프로젝트 진행 중\n",
      "- 탄소 배출 감소를 위한 연료 소비 예측 모델 개발에 초점을 맞춘 2023년 한국산업 및 시스템 공학회 춘계 공동 학술 대회에서 포스터 발표\n",
      "- 2년 6개월의 운영 경험을 통해 7척의 선박에서 센서 데이터를 사용하여 연료 소비를 예측하는 ML, AutoML, Bi-LSTM with Attention, XGB 등을 활용하였으며, 도메인 지식 기반 전처리 및 특징 공학을 수행하였으며, 도메인별 지표 (DP E per day, BPE for overall voyage period, VE per voyage)를 생성함\n",
      "- MLflow를 사용하여 로깅을 수행하였으며, 3개월 동안 회사의 목표 성능인 MAP E 8%를 달성함\n",
      "- 제조 현장에서 D T를 위한 OCR AI 모델 및 실습 자료 개발\n",
      "- 화재 예방 시스템 개발을 위한 데이터 생성 및 라벨링, CCTV 및 실내 연기 발생기를 사용하여 실내 연기 데이터를 생성하고 라벨링하였으며, 주석을 위해 CV A T를 활용함\n",
      "- 건설 장비에서 오일 분류를 위한 머신 러닝 대회에 참가하여 건설 기계에서 운영 중인 오일 상태를 실시간으로 모니터링하기 위한 오일 상태 분류 모델을 개발함\n",
      "- 프로젝트와 관련된 데이터 증강 및 전처리 작업 수행\n",
      "\n",
      "데이터 기반 프로젝트에서 후보자 1은 안전한 선박 항해를 위한 주기관 이상 탐지 대시보드 작성 및 머신 러닝 기술을 사용한 신용카드 사용자 연체 예측 대회에 참가하였습니다. 그들은 전처리, 모델링 및 결과 보고와 같은 작업을 관리하는 데 강력한 리더십 기술을 보여주었습니다. 또한, 특징 공학 및 클래스 불균형 데이터 처리의 중요성에 대한 통찰력을 얻었습니다.\n",
      "\n",
      "수상 경력:\n",
      "\n",
      "* 안전한 선박 운항을 위한 데이터 기반 파랑 예측 조기 경보 서비스 개발, 조선해양 공공데이터 및 빅데이터 활용 경진대회 (한국조선해양기자재연구원 & 부산테크노파크), 2022.12.20 최우수상\n",
      "* D A CON 2021 농식품 가격 예측 AI 경진대회 우수상, 한국농수산식품유통공사 주관, 2021.12.09\n",
      "* COD 해양오염지수를 예측하고, COD가 크게 증가하는 구역을 선별하여 특별관리해역을 제안함, JOISs 2021 해양과학 빅데이터 활용 경진대회 (해양수산부 주최), 2021.11.12 대한원격탐사학회장상\n",
      "* 부산 남구 주차 수요 예측 모델 개발, 한국토지주택공사 주관, 2021.10.28 입선\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:43, 43.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preview:  Candidate No.2 is a machine learning enthusiast with an open mindset and adaptability, who has consistently documented their growth on Notion and blogs. They enjoy collaborating with diverse team members and have participated in various project activities. With a strong passion for continuous self-improvement and a spirit of challenge, they are committed to personal development.\n",
      "\n",
      "Work Experience:\n",
      "1. Dataedu (2020.12 - 2021.02): Worked at a data-driven technology company specializing in consulting and education services related to big data and AI. Contributed to the creation of an effective and accessible learning experience by collecting, processing, and organizing high-quality YouTube content for a new website.\n",
      "2. Alchera (2023.03 - 2023.08): Gained hands-on experience in developing a fire prevention system model from data collection to model development using CVAT for labeling 연기 data, detailed labeling guidelines, and communication with labelers. Developed an OCR model using CNN2RNN to accurately identify the time and coordinates of fires within CCTV footage.\n",
      "\n",
      "Skills:\n",
      "- Machine Learning\n",
      "- Deep Learning\n",
      "- Data Analytics and Visualization\n",
      "- Computer Vision\n",
      "- NLP (Natural Language Processing)\n",
      "- Statistics\n",
      "\n",
      "Tools and Frameworks:\n",
      "- Python\n",
      "- PyTorch\n",
      "- Apache\n",
      "- MySQL\n",
      "- HTML/CSS\n",
      "- Java\n",
      "- JavaScript\n",
      "- Spring\n",
      "- AWS EC2\n",
      "- Hugging Face\n",
      "- SHAPE\n",
      "- SciKit Learn\n",
      "- Django\n",
      "- DockeR\n",
      "\n",
      "Education:\n",
      "- Master's degree in Industrial and Data Engineering (Department of Industrial and Data Engineering) at Pukyong National University (2022.09 - present)\n",
      "- Bachelor of Science in Industrial and Systems Engineering and Computer Science at Pukyoong National University (2022.08)\n",
      "- Pukyong National University (2018.03 - 2022.08)\n",
      "\n",
      "Publications:\n",
      "- Jeong, H., et al. (Feb. 2024). \"Poster: Development of an AI Model for Measurement Instrument Image Recognition in Manufacturing Industry.\" Society for Computational Design and Engineering, p. 1. URL: https://www.cde.or.kr/... \n",
      "\n",
      "==================================================================\n",
      "Preview:  AI Filtering Engine Summary:\n",
      "\n",
      "Candidate No.2 has experience in various projects, including OCR technology for CCTV coordinates and time recognition, predictive modeling for ship fuel consumption, and smart farm automation using vision models and web development. They have skills in Python, PyTorch, AutoML, mlflow, Django, AWS, and Docker.\n",
      "\n",
      "In the OCR project, they developed a model to read coordinates and time from CCTV footage using CNN2RNN and Tesseract OCR techniques. They improved the OCR technology by refining preprocessing methods and adjusting hyperparameters. In the ship fuel consumption prediction project, they used AutoML and mlflow for experiment management while developing models for individual ships to optimize performance.\n",
      "\n",
      "For smart farm automation, Candidate No.2 developed a vision model using CNNRegressor to predict leaf area and created a Django web application for leaf upload and analysis. They plan to expand the project by incorporating real-time streaming data for object recognition of wilted and dry leaves and predicting accurate harvest dates to reduce labor intensity.\n",
      "\n",
      "Candidate No.2's skills and experience make them well-suited for roles in AI, machine learning, and software development related to automation and optimization projects.... \n",
      "\n",
      "==================================================================\n",
      "Preview:  Candidate No.2 has experience in developing a service similar to the current booking system operated by Naver, focusing on implementing content reservation and retrieval functions as well as review creation and viewing features. They have expertise in full-stack development for both front-end and back-end technologies, including HTML, CSS, Java, JavaScript, Spring, MySQL, and Apache.\n",
      "\n",
      "The candidate's involvement in the project aimed to understand the basic web service technology required for the actual implementation of a model. Through this experience, they learned about the processes involved in deploying a model on the web. They have received multiple awards, including the Best Award at the 2022 Hackathon for Counterfeit Product Detection through Customs Inspection and the AI-based Counterfeit Product Detection System Technology Seminar organized by Korea National IT Industry Promotion Agency (NIPA) and Brain Korea 21. They also won the Best Award at the 2022 Shipbuilding and Marine Public Data and Big Data Utilization Competition for developing a fuel consumption prediction model using bulk carrier operation data and interpreting the model using SHAPE and designing a dashboard.\n",
      "\n",
      "The candidate holds an SQLD data qualification certification, which was last updated on May 13, 2024.... \n",
      "\n",
      "==================================================================\n",
      "후보자 2번은 기계 학습에 대한 열정을 가진 사람으로, 열린 사고방식과 적응력을 갖추고 있습니다. 그들은 지속적으로 성장하며, Notion과 블로그를 통해 자신의 성장을 기록하고 있습니다. 다양한 팀원들과 협업하는 것을 즐기며, 다양한 프로젝트 활동에 참여하였습니다. 지속적인 자기계발과 도전을 추구하는 성격을 가지고 있으며, 개인적인 발전에 헌신하고 있습니다.\n",
      "\n",
      "경력:\n",
      "\n",
      "1. Dataedu (2020.12 - 2021.02): 빅데이터와 AI 관련 컨설팅 및 교육 서비스를 제공하는 데이터 기반 기술 회사에서 근무하였습니다. 새로운 웹사이트를 위해 고품질의 유튜브 콘텐츠를 수집, 가공, 정리하여 효과적이고 접근 가능한 학습 경험을 만드는 데 기여하였습니다.\n",
      "2. Alchera (2023.03 - 2023.08): 연기 데이터 라벨링을 위한 CVAT, 상세한 라벨링 가이드라인, 라벨러와의 커뮤니케이션을 통해 화재 예방 시스템 모델을 개발하는 데 참여하였습니다. CCTV 영상 내에서 화재의 시간과 좌표를 정확하게 식별하기 위해 CNN2RNN을 사용한 OCR 모델을 개발하였습니다.\n",
      "\n",
      "기술:\n",
      "\n",
      "* 기계 학습\n",
      "* 딥 러닝\n",
      "* 데이터 분석 및 시각화\n",
      "* 컴퓨터 비전\n",
      "* 자연어 처리 (NLP)\n",
      "* 통계학\n",
      "\n",
      "도구 및 프레임워크:\n",
      "\n",
      "* Python\n",
      "* PyTorch\n",
      "* Apache\n",
      "* MySQL\n",
      "* HTML/CSS\n",
      "* Java\n",
      "* JavaScript\n",
      "* Spring\n",
      "* AWS EC2\n",
      "* Hugging Face\n",
      "* SHAPE\n",
      "* SciKit Learn\n",
      "* Django\n",
      "* Docker\n",
      "\n",
      "학력:\n",
      "\n",
      "* 산업 및 데이터 공학 석사 (산업 및 데이터 공학 학과) at Pukyong National University (2022.09 - 현재)\n",
      "* 산업 및 시스템 공학 및 컴퓨터 과학 학사 at Pukyoong National University (2022.08)\n",
      "* Pukyong National University (2018.03 - 2022.08)\n",
      "\n",
      "출판물:\n",
      "\n",
      "* Jeong, H., et al. (Feb. 2024). \"Poster: Development of an AI Model for Measurement Instrument Image Recognition in Manufacturing Industry.\" Society for Computational Design and Engineering, p. 1. URL: <https://www.cde.or.kr/>\n",
      "\n",
      "AI 필터링 엔진 요약:\n",
      "\n",
      "후보자 2번은 CCTV 좌표 및 시간 인식을 위한 OCR 기술, 선박 연료 소비 예측 모델링, 비전 모델 및 웹 개발을 사용한 스마트 팜 자동화 등 다양한 프로젝트에 참여하였습니다. Python, PyTorch, AutoML, mlflow, Django, AWS, Docker 등의 기술을 보유하고 있습니다.\n",
      "\n",
      "OCR 프로젝트에서는 CNN2RNN과 Tesseract OCR 기술을 사용하여 CCTV 영상에서 좌표와 시간을 읽는 모델을 개발하였습니다. 전처리 방법을 개선하고 하이퍼파라미터를 조정하여 OCR 기술을 개선하였습니다. 선박 연료 소비 예측 프로젝트에서는 AutoML과 mlflow를 사용하여 실험 관리를 하면서 개별 선박에 대한 모델을 개발하여 성능을 최적화하였습니다.\n",
      "\n",
      "스마트 팜 자동화를 위해 후보자 2번은 CNNRegressor를 사용하여 비전 모델을 개발하여 잎 면적을 예측하고, 잎 업로드 및 분석을 위한 Django 웹 애플리케이션을 만들었습니다. 시들음 및 건조 잎의 객체 인식을 위한 실시간 스트리밍 데이터를 통합하고 정확한 수확 날짜를 예측하여 노동 강도를 줄이는 방향으로 프로젝트를 확장할 계획입니다.\n",
      "\n",
      "후보자 2번의 기술과 경험은 자동화 및 최적화 프로젝트와 관련된 AI, 기계 학습 및 소프트웨어 개발 역할에 적합합니다.\n",
      "\n",
      "후보자 2번은 네이버에서 운영하는 현재 예약 시스템과 유사한 서비스 개발 경험이 있으며, 콘텐츠 예약 및 검색 기능 구현과 리뷰 작성 및 조회 기능을 중점적으로 개발하였습니다. HTML, CSS, Java, JavaScript, Spring, MySQL, Apache 등 프론트엔드와 백엔드 기술 모두에 대한 풀스택 개발 전문성을 보유하고 있습니다.\n",
      "\n",
      "해당 프로젝트는 실제 모델 구현에 필요한 기본적인 웹 서비스 기술을 이해하기 위해 진행되었습니다. 이를 통해 웹에 모델을 배포하는 과정에 대해 학습하였습니다. 2022년 해커톤에서 관세청을 통한 위조품 탐지 분야 최우수상, 한국정보통신산업진흥원(NIPA)과 브레인코리아21이 주최한 AI 기반 위조품 탐지 시스템 기술 세미나에서 최우수상을 수상하였습니다. 또한, 2022년 조선해양 공공데이터 및 빅데이터 활용 경진대회에서 벌크선 운항 데이터를 활용한 연료 소모량 예측 모델 개발 및 SHAPE를 활용한 모델 해석, 대시보드 설계로 최우수상을 수상하였습니다.\n",
      "\n",
      "해당 후보자는 SQLD 데이터 자격증을 보유하고 있으며, 자격증 갱신일은 2024년 5월 13일입니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [01:27, 43.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preview:  Candidate No.3 is a highly motivated and curious data scientist with over four years of professional experience in transforming business goals into data-driven results through explanatory, diagnostic, predictive, and prescriptive analysis. They have expertise in various big data analytics tools and platforms such as Python, SQL, PySpark, TensorFlow, PyTorch, and Zeppelin. Additionally, they possess skills in deploying machine learning models to analytical dashboards or APIs and knowledge of microservices.\n",
      "\n",
      "Education:\n",
      "- Bachelor's degree in Engineering from the University of Indonesia (UI) with a GPA of 3.21/4.00\n",
      "- Certificate in Data Science and Machine Learning Engineering from Purwadhika Digital Technology School with a score of 93.5/100\n",
      "- Master's degree in Industrial and Data Science Engineering from Pukyoeng National University (Busan University of Technology) and PuSan National University, joint program with a GPA of 4.33/4.50\n",
      "- Doctoral candidate in Industrial and Data Science Engineering at Pukyoeng National University (Busan University of Technology) and PuSan National University, joint program\n",
      "\n",
      "Work Experience:\n",
      "- Internship at PT. Chevron Pacific Indonesia (CPI), Well Development Team, completed with excellent performance\n",
      "- Internship project at PT. PertaMina (Persero) for CO2 EOR pipeline material prediction model\n",
      "- Maintenance Engineer at Asia Pacific Resources International Holding Ltd (APRIHL) for rotary kiln and wastewater treatment plant machinery maintenance\n",
      "- Data Scientist, Senior Data Scientist at PT. Metra-Net (by Telkom Indonesia), responsible for explanatory, diagnostic, predictive, and prescriptive analysis... \n",
      "\n",
      "==================================================================\n",
      "Preview:  Candidate No.3 is a highly skilled Data Scientist with expertise in descriptive, diagnostic, predictive, and prescriptive analysis. They have experience in transforming business goals into data-driven results by building data marts and modeling. The candidate has proficiency in using analytical tools to support data analysis and effectively communicates findings through interpretations. They also possess strong technical documentation skills.\n",
      "\n",
      "Candidate No.3 holds a Master's degree in Data Science from Business Analytics Lab, Industrial Data Science Engineering PKNU, and is currently pursuing a Ph.D. in Data Science. Their research interests include the impact of machine learning models on business processes. They have experience in server management from 2014 to 2018, with additional work experience in various roles from 2017 to present.\n",
      "\n",
      "Summary:\n",
      "Candidate No.3 is a skilled Data Scientist with expertise in data analysis and modeling. They hold a Master's degree in Data Science and are pursuing a Ph.D., focusing on the impact of machine learning models on business processes. With experience in server management and various roles, they possess strong technical documentation skills and can effectively communicate findings through interpretations.... \n",
      "\n",
      "==================================================================\n",
      "Preview:  Candidate No.3 is a highly skilled data scientist with expertise in model and algorithm development, analysis dashboard creation, API integration, and project management. They have experience working on various research projects at Daewoong Pharmaceuticals, including spray process optimization, utility data control algorithms, and article generation.\n",
      "\n",
      "Candidate No.3 has also been actively involved in organizational activities, serving as the vice president of the Indonesian University Riau Student Association and a member of the organization's audit committee. They have received numerous awards for their achievements, including winning the DRB Same Machine Learning Contest and placing second in the Yonha News Data Science Hackathon, both organized by Korea Information Industry Promotion Agency (NIPA) and Brain Korea 21 (BK21).\n",
      "\n",
      "Candidate No.3's technical skills include ETL, data analytics and visualization, business scientist, machine learning, deep learning, Spark, SQL, generative models, transfer learning, text processing, computer vision, imputatation models, explainable AI, basic reinforcement learning, statistics, business process mining, model deployment, dashboard analytics, REST API, microservices, and more. They are proficient in various tools and frameworks such as Python 3, Apache Spark (PySpark), Jupyter, Scikitlearn, Spark ML-Lib, Apache Zeppelin, MySQL, Tensorflow/Keras, PyTorch, HTML/CSS, Docker, Cloudera (CDSW), Dasht, Flask, MetaBase, Streamlit, Apache Hue, Hugging Face, SHAPE, Unit, basic C#, basic Java, AWS EC2, and MLToolkit.\n",
      "\n",
      "In summary, Candidate No.3 is a highly skilled data scientist with extensive experience in various research projects, organizational activities, and numerous awards for their achievements. They possess a wide range of technical skills and proficiency in multiple tools and frameworks, making them an excellent candidate for any data science-related position.... \n",
      "\n",
      "==================================================================\n",
      "Preview:  Candidate No.3 has experience in various technologies such as Apache Hue, Hugging Face, SHAPE, UnitY, basic C# and Java programming languages, AWS EC2, and MLToolkit. They have worked from Jul'2015 to Jun'2016, and then again from 2022 to the present. Their work experience includes a position held from Apr'2022 to Jun'2017.\n",
      "\n",
      "Remaining job-related information:\n",
      "\n",
      "* Education: [Education details removed for privacy]\n",
      "* Work Experience:\n",
      "  + [Previous company/organization] (Jul'2015 - Jun'2016)\n",
      "  + [Current company/organization] (Apr'2022 - Present)\n",
      "* Skills: Apache Hue, Hugging Face, SHAPE, UnitY, basic C# and Java programming languages, AWS EC2, MLToolkit\n",
      "* Awards: [Awards details removed for privacy]... \n",
      "\n",
      "==================================================================\n",
      "후보자 3번은 데이터 과학 분야에서 높은 동기와 호기심을 가진 전문가로, 설명적, 진단적, 예측적, 처방적 분석을 통해 비즈니스 목표를 데이터 기반 결과로 변환하는 데 4년 이상의 전문 경력을 가지고 있습니다. 그들은 Python, SQL, PySpark, TensorFlow, PyTorch, Zeppelin과 같은 다양한 빅 데이터 분석 도구 및 플랫폼에 대한 전문 지식을 보유하고 있으며, 기계 학습 모델을 분석 대시 보드 또는 API에 배포하는 기술과 마이크로 서비스에 대한 지식을 보유하고 있습니다.\n",
      "\n",
      "학력:\n",
      "\n",
      "* 인도네시아 대학교 (UI) 공학 학사, GPA 3.21/4.00\n",
      "* Purwadhika Digital Technology School에서 데이터 과학 및 기계 학습 공학 인증서, 93.5/100 점수\n",
      "* Pukyoeng National University (Busan University of Technology) 및 PuSan National University에서 산업 및 데이터 과학 공학 석사, 공동 프로그램, GPA 4.33/4.50\n",
      "* Pukyoeng National University (Busan University of Technology) 및 PuSan National University에서 산업 및 데이터 과학 공학 박사 후보\n",
      "\n",
      "경력:\n",
      "\n",
      "* PT. Chevron Pacific Indonesia (CPI)에서 인턴십, Well Development Team, 우수한 성과로 완료\n",
      "* PT. PertaMina (Persero)에서 인턴십 프로젝트, CO2 EOR 파이프 라인 재료 예측 모델\n",
      "* Asia Pacific Resources International Holding Ltd (APRIHL)에서 유지 보수 엔지니어, 회전 킬른 및 폐수 처리 공장 기계 유지 보수\n",
      "* PT. Metra-Net (by Telkom Indonesia)에서 데이터 과학자, 시니어 데이터 과학자, 설명적, 진단적, 예측적, 처방적 분석 담당\n",
      "\n",
      "후보자 3번은 모델 및 알고리즘 개발, 분석 대시 보드 생성, API 통합 및 프로젝트 관리에 대한 전문 지식을 가진 숙련 된 데이터 과학자입니다. 그들은 Daewoong Pharmaceuticals에서 스프레이 공정 최적화, 유틸리티 데이터 제어 알고리즘 및 기사 생성을 포함한 다양한 연구 프로젝트에 참여했습니다.\n",
      "\n",
      "후보자 3번은 또한 인도네시아 대학교 Riau 학생 협회의 부회장을 역임하고 조직의 감사 위원회의 일원으로 활동하는 등 조직 활동에 적극적으로 참여했습니다. 그들은 DRB Same Machine Learning Contest에서 우승하고 Yonha News Data Science Hackathon에서 2 위를 차지하는 등 다양한 상을 수상했습니다. 이 두 대회는 모두 Korea Information Industry Promotion Agency (NIPA)와 Brain Korea 21 (BK21)이 주최했습니다.\n",
      "\n",
      "기술적 기술:\n",
      "\n",
      "* ETL\n",
      "* 데이터 분석 및 시각화\n",
      "* 비즈니스 과학자\n",
      "* 기계 학습\n",
      "* 딥 러닝\n",
      "* Spark\n",
      "* SQL\n",
      "* 생성 모델\n",
      "* 전이 학습\n",
      "* 텍스트 처리\n",
      "* 컴퓨터 비전\n",
      "* 대입 모델\n",
      "* 설명 가능한 AI\n",
      "* 기본 강화 학습\n",
      "* 통계\n",
      "* 비즈니스 프로세스 마이닝\n",
      "* 모델 배포\n",
      "* 대시 보드 분석\n",
      "* REST API\n",
      "* 마이크로 서비스\n",
      "\n",
      "후보자 3번은 Apache Spark (PySpark), Jupyter, Scikitlearn, Spark ML-Lib, Apache Zeppelin, MySQL, Tensorflow/Keras, PyTorch, HTML/CSS, Docker, Cloudera (CDSW), Dasht, Flask, MetaBase, Streamlit, Apache Hue, Hugging Face, SHAPE, Unit, 기본 C#, 기본 Java, AWS EC2 및 MLToolkit과 같은 다양한 도구 및 프레임워크에 능숙합니다.\n",
      "\n",
      "요약하면, 후보자 3번은 다양한 연구 프로젝트, 조직 활동 및 다양한 상을 수상한 경험이 있는 숙련 된 데이터 과학자입니다. 그들은 광범위한 기술 기술과 다양한 도구 및 프레임워크에 대한 숙련도를 보유하고 있어 데이터 과학 관련 직책에 탁월한 후보자입니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [02:02, 39.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preview:  Candidate No.4 is a SAP HCM consultant with experience in full cycle implementation projects at PT. Pelabuhan Indonesia Raya (PELINDO). They have expertise in various fields such as SAP Time Management, SAP Payroll, SAP Travel Management, SAP Organization Management, SAP Personnel Administration, SAP FIORI (ES/MS), and SAP Personnel Cost Planning. The candidate successfully completed a challenging project involving data and system integration between four previously separate companies, demonstrating strong strategic planning, public speaking, negotiation, teamwork, problem-solving, critical thinking, and time management skills. Additionally, they are proficient in four languages, which enhances their consultant capabilities and ability to work with diverse clients.\n",
      "\n",
      "Work Experience:\n",
      "Company: NTT DATA BUSINESS SOLUTIONS (Indonesia)\n",
      "Duration: May 2022 - June 2023\n",
      "Role: Junior SAP HCM Consultant\n",
      "Project: PT. Pelabuhan Indonesia Raya\n",
      "Phase 1 (Implementation of SAP HCM): June 2022 - March 2023... \n",
      "\n",
      "==================================================================\n",
      "Preview:  As a Junior SAP HCM consultant, Candidate No.4 worked on the PT. Pelabuhan Indonesia Raya project from June 2022 to March 2023 and later in Phase 2 from March to May 2023. Their responsibilities included creating blueprint documents for the HCM module, setting up customization configurations based on business requirements, designing functional specifications and program testing for reports, interfaces, conversions, enhancements, and forms. They also worked on system integration with other SAP modules and surrounding systems, provided user training, performed system integration tests, created user manuals and configuration documents for the HCM module, conducted data migration and cutover activities, and supported post-go-live operations.\n",
      "\n",
      "Key skills:\n",
      "- SAP HCM implementation and customization\n",
      "- Functional specifications and program testing\n",
      "- System integration with other modules and surrounding systems\n",
      "- User training and documentation creation\n",
      "- Data migration and cutover management\n",
      "- Post-go-live support... \n",
      "\n",
      "==================================================================\n",
      "Preview:  Design functional specifications and program testing for Report, Interface, Conversion, Enhancement, and Form. Create data testing and work integration with other SAP modules & surrounding systems.\n",
      "\n",
      "Education:\n",
      "Candidate No.4 graduated from Gadjah Mada University, Indonesia with a Bachelor of International Relations. Cumulative GPA: 3.55/4 (CUMLAUDE Graduate).\n",
      "\n",
      "Achievement:\n",
      "Won the PKMI KBMI - Ministry of Education and Culture Indonesia Award in 2021 for the project \"Pinjahan.id: First Move Jaasa Logistiik Indonesia based on Technology Application.\" Conducted feasibility study, explained business design and development. Successfully managed funding up to 21 million for this business as a pitching team member.\n",
      "\n",
      "Skills:\n",
      "Language proficiency in Bahasa (native), English (proficient), Korean (basic level), Mandarin (beginner). Advanced skills in MS Word, Excel, and PowerPoint.... \n",
      "\n",
      "==================================================================\n",
      "Preview:  Candidate No.4 worked as a team member on the Project Roll Out Implementation for PT Pelabuhan Indonesia Raya, which involved merging four companies into one under the new name. The company operates 94 ports across all Indonesian provinces and sought to create an integrated system while adhering to existing regulations. The consultant's role included not only building the SAP HCM system but also integrating it with surrounding systems, ensuring data migration was complete, and addressing post-implementation issues in the second phase of the project. Submodules implemented include SAP Time Management, SAP Payroll, SAP Organization Management, and SAP Personnel Administration. The consultant successfully delivered the system with satisfactory results, leading to continued collaboration on the project's second phase.... \n",
      "\n",
      "==================================================================\n",
      "Preview:  AI Filtering Engine Output:\n",
      "\n",
      "Summary of Candidate No.4's Qualifications and Experience:\n",
      "\n",
      "Candidate No.4 has extensive experience in implementing submodules for various HR management systems, including SAP Time Management, SAP Payroll, SAP Organization Management, SAP Personnel Administration, SAP Travel Management, SAP Fiori (Employee Self Service), and SAP Personnel Cost Planning. They have conducted user requirement gathering and business process workshops to analyze the gaps between current and desired HR management processes.\n",
      "\n",
      "Candidate No.4 has established, developed, and evaluated requirements, business rules, business cases, and solution designs for HR management systems. They have set up customization configurations based on business blueprints and designed functional specifications and program testing for reports, interfaces, conversions, enhancements, and forms.\n",
      "\n",
      "Candidate No.4 has worked on integrating HR management systems with other SAP modules and surrounding systems. They have designed and developed authorization role matrices, test plan scenarios, UAT scripts, training materials, end-to-end testing of delivered solutions based on test plan scenarios, key user and end user training, integration tests, user acceptance tests, cutover strategy design, data migration, and post-go-live support.\n",
      "\n",
      "Candidate No.4's expertise in HR management systems implementation and project management makes them a valuable asset to any organization looking to improve their HR processes and systems.... \n",
      "\n",
      "==================================================================\n",
      "Candidate No.4 is a highly skilled SAP HCM consultant with extensive experience in implementing various HR management submodules, including SAP Time Management, SAP Payroll, SAP Organization Management, SAP Personnel Administration, SAP Travel Management, SAP Fiori (Employee Self Service), and SAP Personnel Cost Planning. They have conducted user requirement gathering and business process workshops to analyze the gaps between current and desired HR management processes.\n",
      "\n",
      "Candidate No.4 has established, developed, and evaluated requirements, business rules, business cases, and solution designs for HR management systems. They have set up customization configurations based on business blueprints and designed functional specifications and program testing for reports, interfaces, conversions, enhancements, and forms.\n",
      "\n",
      "Candidate No.4 has worked on integrating HR management systems with other SAP modules and surrounding systems. They have designed and developed authorization role matrices, test plan scenarios, UAT scripts, training materials, end-to-end testing of delivered solutions based on test plan scenarios, key user and end user training, integration tests, user acceptance tests, cutover strategy design, data migration, and post-go-live support.\n",
      "\n",
      "Candidate No.4's expertise in HR management systems implementation and project management makes them a valuable asset to any organization looking to improve their HR processes and systems.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [02:30, 37.69s/it]\n"
     ]
    }
   ],
   "source": [
    "for i, filename in tqdm(enumerate(file_list)):\n",
    "    candidate_num = f\"Candidate No.{i+1}\"\n",
    "    vectordb = update_vector_db(candidate_num=candidate_num, file_name=filename, \n",
    "                                filter_embedding=filter_embedding, filter_llm=filter_llm,\n",
    "                                solar_embedding=solar_embedding, solar_llm=solar_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f8385ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T15:43:48.527425Z",
     "start_time": "2024-08-27T15:43:48.514549Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(vectordb._collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef2dba1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T15:54:17.623369Z",
     "start_time": "2024-08-27T15:54:17.616817Z"
    }
   },
   "outputs": [],
   "source": [
    "# preparing our custom prompt\n",
    "metrics_prompt_template = \"\"\"\n",
    "        You are a helpful AI SCOUT BOT! Your name is scouty.\n",
    "        If the context is not relevant or is difficult to provide a specific definition or detailed understanding, \n",
    "        please answer the question by using your own knowledge about the topic\n",
    "        \n",
    "        If question asking related with calculate or evaluate candidate resumes You should following below instructions.\n",
    "        \n",
    "        Here are the metrics to evaluate candidate resumes. \n",
    "        For all candidates, please calculate the following metrics, and all metric scores should be in the range of 1(bad) to 5(good). \n",
    "        Please provide the results in a JSON format, where the keys are the candidate names, and the values are another JSON object containing the scores for each metric.\n",
    "\n",
    "        Metrics to evaluate:\n",
    "        (1). experience: Measure the total years of relevant work experience.\n",
    "        (2). relevance: Assess how closely the applicant's experience aligns with the job domain.\n",
    "        (3). education: Evaluate the level and relevance of the applicant's education to the job requirement.\n",
    "        (4). skills: Rate the proficiency in key technical skills required for the job.\n",
    "\n",
    "        The output should be in the following format:\n",
    "        {{\n",
    "            \"Candidate Name 1\": {{\n",
    "                \"experience\": X,\n",
    "                \"relevance\": Y,\n",
    "                \"education\": Z,\n",
    "                \"skills\": W,\n",
    "            }},\n",
    "            ...\n",
    "        }}\n",
    "        \n",
    "        {context}\n",
    "        \n",
    "        Question: {question}\n",
    "        \"\"\"\n",
    "Metrics_PROMPT = PromptTemplate(\n",
    "                    template=metrics_prompt_template, \n",
    "                    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "# we define memory for chat history\n",
    "metrics_memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "# retrieval chain\n",
    "metrics_qa = ConversationalRetrievalChain.from_llm(\n",
    "    chat_llm,\n",
    "    retriever=vectordb.as_retriever(search_type=\"mmr\",\n",
    "                                    search_kwargs={'k': 10, 'fetch_k': 50}),\n",
    "    chain_type=\"stuff\", # if want to use other chain type, you may need other parameter setup for ConversationRetrievalChain \n",
    "    memory=metrics_memory,\n",
    "    combine_docs_chain_kwargs={\"prompt\": Metrics_PROMPT}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a27124dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T15:54:21.927056Z",
     "start_time": "2024-08-27T15:54:18.597091Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 50 is greater than number of elements in index 4, updating n_results = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   \"Candidate No.1\": {     \"experience\": 4,     \"relevance\": 4,     \"education\": 4,     \"skills\": 4   },   \"Candidate No.2\": {     \"experience\": 3,     \"relevance\": 3,     \"education\": 3,     \"skills\": 3   },   \"Candidate No.3\": {     \"experience\": 5,     \"relevance\": 5,     \"education\": 5,     \"skills\": 5   },   \"Candidate No.4\": {     \"experience\": 2,     \"relevance\": 2,     \"education\": 2,     \"skills\": 2   } }\n"
     ]
    }
   ],
   "source": [
    "job_domains = [\"team leader\", \"data scince\", \"machine learning\"]\n",
    "skills_list = [\"python\", \"pytorch\", \"api\"]\n",
    "# education = \"msc\"\n",
    "question = f\"\"\"\n",
    "I should rank all candidates based on their background to be in job domain {job_domains} and have skills {skills_list} with scale in range 1 to 5.\n",
    "\"\"\"\n",
    "metrics_result = metrics_qa.invoke({\"question\": question})\n",
    "metrics_result = metrics_result['answer'].replace('\\n\\n',' ').replace('\\n',' ')\n",
    "print(metrics_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fee8a703",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T15:55:41.809291Z",
     "start_time": "2024-08-27T15:55:41.803642Z"
    }
   },
   "outputs": [],
   "source": [
    "# preparing our custom prompt\n",
    "prompt_template = f\"\"\"\n",
    "        You are a helpful AI SCOUT BOT! Your name is scouty. \n",
    "        please answer the question by using your own knowledge about the topic\n",
    "        please only refer based on this metrics for ranking information of each cadidates : {metrics_result.replace(\"}\",'').replace(\"{\",\"\")}\n",
    "        please provide a concise answer in 5 sentences or less.\n",
    "        At the end of your answer, explicitly state that you need to review it further.\n",
    "        \n",
    "        {{context}}\n",
    "        \n",
    "        Question: {{question}}\n",
    "        \"\"\"\n",
    "PROMPT = PromptTemplate(\n",
    "                    template=prompt_template, \n",
    "                    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "# we define memory for chat history\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "# retrieval chain\n",
    "qa = ConversationalRetrievalChain.from_llm(\n",
    "    chat_llm,\n",
    "    retriever=vectordb.as_retriever(search_type=\"mmr\",\n",
    "                                    search_kwargs={'k': 10, 'fetch_k': 50}),\n",
    "    chain_type=\"stuff\", # if want to use other chain type, you may need other parameter setup for ConversationRetrievalChain \n",
    "    memory=memory,\n",
    "    combine_docs_chain_kwargs={\"prompt\": PROMPT}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d5e39841",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T15:55:45.153991Z",
     "start_time": "2024-08-27T15:55:42.968370Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 50 is greater than number of elements in index 4, updating n_results = 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'제공된 정보를 기반으로, 후보자 3은 데이터 사이언스 분야에서 높은 동기와 호기심을 가진 전문가로서, 다양한 연구 프로젝트, 조직 활동, 그리고 다양한 수상 경력을 가지고 있습니다. 그들은 다양한 빅 데이터 분석 도구와 플랫폼에 대한 전문 지식을 가지고 있으며, 다양한 기술 스킬을 보유하고 있습니다. 따라서, 후보자 3은 데이터 사이언티스트 팀 리더에 가장 적합한 후보자로 보입니다. 그러나, 더 자세한 검토를 통해 최종 결정을 내리는 것이 좋습니다.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"\"\"\n",
    "직무 관련 점수를 고려했을 때, 지원자 중에 데이터 사이언티스트 팀 리더에 가장 적합한 후보자를 알려줘.\n",
    "\"\"\"\n",
    "result = qa.invoke({\"question\": question})\n",
    "result['answer'].replace('\\n\\n',' ').replace('\\n',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1ff0e380",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T15:55:54.533212Z",
     "start_time": "2024-08-27T15:55:52.155847Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 50 is greater than number of elements in index 4, updating n_results = 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'후보자 3은 다양한 연구 프로젝트, 조직 활동, 그리고 다양한 수상 경력을 가진 숙련된 데이터 과학자입니다. 그들은 광범위한 기술 스킬과 다양한 도구 및 프레임워크에 대한 숙련도를 가지고 있어 데이터 과학 관련 직무에 탁월한 후보자입니다.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"\"\"\n",
    "다른 후보자와 비교했을 때, 해당 후보자의 강점이 뭐야?\n",
    "\"\"\"\n",
    "result = qa.invoke({\"question\": question})\n",
    "result['answer'].replace('\\n\\n',' ').replace('\\n',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "22117666",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T15:56:04.214732Z",
     "start_time": "2024-08-27T15:56:00.457859Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 50 is greater than number of elements in index 4, updating n_results = 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1. 데이터 사이언스 프로젝트를 성공적으로 이끈 경험에 대해 이야기해주세요. 어떤 도전과제가 있었고, 어떻게 해결했나요? 2. 팀원들 간의 협업과 지식 공유를 어떻게 촉진하시나요? 팀 리더로서 어떤 역할을 맡으시나요? 3. 데이터 사이언스 분야에서의 최신 동향과 기술에 대해 어떻게 업데이트하고, 이를 팀에 적용하는 방법을 설명해주세요.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"\"\"\n",
    "면접을 진행할 때에, 해당 후보자에게 면접에서 할만한 질문 3가지를 리스트업 해줘.\n",
    "\"\"\"\n",
    "result = qa.invoke({\"question\": question})\n",
    "result['answer'].replace('\\n\\n',' ').replace('\\n',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f9039329",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T15:56:34.679259Z",
     "start_time": "2024-08-27T15:56:32.220828Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 50 is greater than number of elements in index 4, updating n_results = 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'후보자 1번은 다양한 분야에서 경험을 쌓은 AI 엔지니어로, 커뮤니케이션 및 협업 능력이 뛰어납니다. 그들은 지속적으로 노션에 학습 일지를 작성하며, 자기계발과 연구를 통해 새로운 지식과 기술을 습득하는 데 열정적입니다. 최근에는 LLM, LoRA, RA G 방법론에 관심을 가지고 관련 연구에 적극적으로 참여하고 있습니다.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"\"\"\n",
    "후보자 3번 외에 다른 후보자를 한 사람만 더 추천해줘.\n",
    "\"\"\"\n",
    "result = qa.invoke({\"question\": question})\n",
    "result['answer'].replace('\\n\\n',' ').replace('\\n',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ebeb1f86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T15:56:45.903491Z",
     "start_time": "2024-08-27T15:56:43.632891Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 50 is greater than number of elements in index 4, updating n_results = 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'후보자 1번은 부경대학교와 부산대학교에서 산업 및 데이터 공학 석사 학위를 취득하였습니다 (2023.03). 또한, 부경대학교에서 시스템 관리 공학 학사 학위를 취득하였으며, 전공은 기술 데이터 공학입니다 (2017-2023.02).'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"\"\"\n",
    "후보자 1번의 학력과 전공은 어떻게 돼?\n",
    "\"\"\"\n",
    "result = qa.invoke({\"question\": question})\n",
    "result['answer'].replace('\\n\\n',' ').replace('\\n',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e6a98a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b76ce44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289d68eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc1ba2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scout_mates_env",
   "language": "python",
   "name": "scout_mates_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
